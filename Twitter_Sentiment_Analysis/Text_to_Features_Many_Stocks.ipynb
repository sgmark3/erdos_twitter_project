{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Recent Tweets mentioning Company Name and/or Stock Hash/Cashtags\n",
    "\n",
    "In this file, we preprocess the raw stock data for all companies. In particular, we extract the word counts and Vader scores, then we remove the entries without non-neutral sentiments, and we finally remove the text column from the tables. The preprocessed data will be saved in the csv files called `df_CompanyName_features_added.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweet_path = \"/Users/josht/Documents/Tweets_raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us extract the list of all file names in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = listdir(raw_tweet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we import the preprocessing script and run it on all the files whose names are in `filename_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Text_to_Features_Script as script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 407 . . . . . . . . . .\n",
      "Salesforce finished\n",
      "Working on 408 . . . . . . . . . .\n",
      "Schlumberger finished\n",
      "Working on 409 . . . . . . . . . .\n",
      "SeagateTechnology finished\n",
      "Working on 410 . . . . . . . . . .\n",
      "SealedAir finished\n",
      "Working on 411 . . . . . . . . . .\n",
      "SempraEnergy finished\n",
      "Working on 412 . . . . . . . . . .\n",
      "ServiceNow finished\n",
      "Working on 413 . . . . . . . . . .\n",
      "Sherwin-Williams finished\n",
      "Working on 414 . . . . . . . . . .\n",
      "SimonPropertyGroup finished\n",
      "Working on 415 . . . . . . . . . .\n",
      "SkyworksSolutions finished\n",
      "Working on 416 . . . . . . . . . .\n",
      "Snap-on finished\n",
      "Working on 417 . . . . . . . . . .\n",
      "SouthernCompany finished\n",
      "Working on 418 . . . . . . . . . .\n",
      "SouthwestAirlines finished\n",
      "Working on 419 . . . . . . . . . .\n",
      "StanleyBlack_Decker finished\n",
      "Working on 420 . . . . . . . . . .\n",
      "Starbucks finished\n",
      "Working on 421 . . . . . . . . . .\n",
      "StateStreetCorporation finished\n",
      "Working on 422 . . . . . . . . . .\n",
      "Steris finished\n",
      "Working on 423 . . . . . . . . . .\n",
      "StrykerCorporation finished\n",
      "Working on 424 . . . . . . . . . .\n",
      "SynchronyFinancial finished\n",
      "Working on 425 . . . . . . . . . .\n",
      "Synopsys finished\n",
      "Working on 426 . . . . . . . . . .\n",
      "Sysco finished\n",
      "Working on 427 . . . . . . . . . .\n",
      "T-MobileUS finished\n",
      "Working on 428 . . . . . . . . . .\n",
      "T.RowePrice finished\n",
      "Working on 429 . . . . . . . . . .\n",
      "TEConnectivity finished\n",
      "Working on 430 . . . . . . . . . .\n",
      "TJXCompanies finished\n",
      "Working on 431 . . . . . . . . . .\n",
      "Take-TwoInteractive finished\n",
      "Working on 432 . . . . . . . . . .\n",
      "Tapestry finished\n",
      "Working on 433 . . . . . . . . . .\n",
      "TargetCorporation finished\n",
      "Working on 434 . . . . . . . . . .\n",
      "TeledyneTechnologies finished\n",
      "Working on 435 . . . . . . . . . .\n",
      "Teleflex finished\n",
      "Working on 436 . . . . . . . . . .\n",
      "Teradyne finished\n",
      "Working on 437 . . . . . . . . . .\n",
      "Tesla finished\n",
      "Working on 438 . . . . . . . . . .\n",
      "TexasInstruments finished\n",
      "Working on 439 . . . . . . . . . .\n",
      "Textron finished\n",
      "Working on 440 . . . . . . . . . .\n",
      "TheCooperCompanies finished\n",
      "Working on 441 . . . . . . . . . .\n",
      "TheHartford finished\n",
      "Working on 442 . . . . . . . . . .\n",
      "TheHersheyCompany finished\n",
      "Working on 443 . . . . . . . . . .\n",
      "TheMosaicCompany finished\n",
      "Working on 444 . . . . . . . . . .\n",
      "TheTravelersCompanies finished\n",
      "Working on 445 . . . . . . . . . .\n",
      "TheWaltDisneyCompany finished\n",
      "Working on 446 . . . . . . . . . .\n",
      "ThermoFisherScientific finished\n",
      "Working on 447 . . . . . . . . . .\n",
      "TractorSupplyCompany finished\n",
      "Working on 448 . . . . . . . . . .\n",
      "TraneTechnologies finished\n",
      "Working on 449 . . . . . . . . . .\n",
      "TransDigmGroup finished\n",
      "Working on 450 . . . . . . . . . .\n",
      "Trimble finished\n",
      "Working on 451 . . . . . . . . . .\n",
      "TruistFinancial finished\n",
      "Working on 452 . . . . . . . . . .\n",
      "Twitter finished\n",
      "Working on 453 . . . . . . . . . .\n",
      "TylerTechnologies finished\n",
      "Working on 454 . . . . . . . . . .\n",
      "TysonFoods finished\n",
      "Working on 455 . . . . . . . . . .\n",
      "U.S.Bancorp finished\n",
      "Working on 456 . . . . . . . . . .\n",
      "UDR finished\n",
      "Working on 457 . . . . . . . . . .\n",
      "UltaBeauty finished\n",
      "Working on 458 . . . . . . . . . .\n",
      "UnderArmour(ClassA) finished\n",
      "Working on 459 . . . . . . . . . .\n",
      "UnderArmour(ClassC) finished\n",
      "Working on 460 . . . . . . . . . .\n",
      "UnionPacific finished\n",
      "Working on 461 . . . . . . . . . .\n",
      "UnitedAirlines finished\n",
      "Working on 462 . . . . . . . . . .\n",
      "UnitedHealthGroup finished\n",
      "Working on 463 . . . . . . . . . .\n",
      "UnitedParcelService finished\n",
      "Working on 464 . . . . . . . . . .\n",
      "UnitedRentals finished\n",
      "Working on 465 . . . . . . . . . .\n",
      "UniversalHealthServices finished\n",
      "Working on 466 . . . . . . . . . .\n",
      "VFCorporation finished\n",
      "Working on 467 . . . . . . . . . .\n",
      "ValeroEnergy finished\n",
      "Working on 468 . . . . . . . . . .\n",
      "Ventas finished\n",
      "Working on 469 . . . . . . . . . .\n",
      "Verisign finished\n",
      "Working on 470 . . . . . . . . . .\n",
      "VeriskAnalytics finished\n",
      "Working on 471 . . . . . . . . . .\n",
      "VerizonCommunications finished\n",
      "Working on 472 . . . . . . . . . .\n",
      "VertexPharmaceuticals finished\n",
      "Working on 473 . . . . . . . . . .\n",
      "ViacomCBS finished\n",
      "Working on 474 . . . . . . . . . .\n",
      "Viatris finished\n",
      "Working on 475 . . . . . . . . . .\n",
      "Visa finished\n",
      "Working on 476 . . . . . . . . . .\n",
      "VornadoRealtyTrust finished\n",
      "Working on 477 . . . . . . . . . .\n",
      "VulcanMaterials finished\n",
      "Working on 478 . . . . . . . . . .\n",
      "W.R.BerkleyCorporation finished\n",
      "Working on 479 . . . . . . . . . .\n",
      "W.W.Grainger finished\n",
      "Working on 480 . . . . . . . . . .\n",
      "WECEnergyGroup finished\n",
      "Working on 481 . . . . . . . . . .\n",
      "Wabtec finished\n",
      "Working on 482 . . . . . . . . . .\n",
      "WalgreensBootsAlliance finished\n",
      "Working on 483 . . . . . . . . . .\n",
      "Walmart finished\n",
      "Working on 484 . . . . . . . . . .\n",
      "WasteManagement finished\n",
      "Working on 485 . . . . . . . . . .\n",
      "WatersCorporation finished\n",
      "Working on 486 . . . . . . . . . .\n",
      "WellsFargo finished\n",
      "Working on 487 . . . . . . . . . .\n",
      "Welltower finished\n",
      "Working on 488 . . . . . . . . . .\n",
      "WestPharmaceuticalServices finished\n",
      "Working on 489 . . . . . . . . . .\n",
      "WestRock finished\n",
      "Working on 490 . . . . . . . . . .\n",
      "WesternDigital finished\n",
      "Working on 491 . . . . . . . . . .\n",
      "WesternUnion finished\n",
      "Working on 492 . . . . . . . . . .\n",
      "Weyerhaeuser finished\n",
      "Working on 493 . . . . . . . . . .\n",
      "WhirlpoolCorporation finished\n",
      "Working on 494 . . . . . . . . . .\n",
      "WilliamsCompanies finished\n",
      "Working on 495 . . . . . . . . . .\n",
      "WillisTowersWatson finished\n",
      "Working on 496 . . . . . . . . . .\n",
      "WynnResorts finished\n",
      "Working on 497 . . . . . . . . . .\n",
      "XcelEnergy finished\n",
      "Working on 498 . . . . . . . . . .\n",
      "Xilinx finished\n",
      "Working on 499 . . . . . . . . . .\n",
      "Xylem finished\n",
      "Working on 500 . . . . . . . . . .\n",
      "Yum!Brands finished\n",
      "Working on 501 . . . . . . . . . .\n",
      "ZebraTechnologies finished\n",
      "Working on 502 . . . . . . . . . .\n",
      "ZimmerBiomet finished\n",
      "Working on 503 . . . . . . . . . .\n",
      "ZionsBancorp finished\n",
      "Working on 504 . . . . . . . . . .\n",
      "Zoetis finished\n",
      "Working on 505 . . . . . . . . . .\n",
      "eBay finished\n"
     ]
    }
   ],
   "source": [
    "# This line is to preprocess all the files\n",
    "i = 407\n",
    "for file in filename_list[406:]:\n",
    "    print(\"Working on\", i, \". . . . . . . . . .\")\n",
    "    script.main(file)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_Salesforce.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_list[406]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent Tweets from Prominent Users\n",
    "\n",
    "For Tweets from specific users, first re-define the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweet_path2 = \"/Users/josht/Documents/Tweets_processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "filename_list2 = listdir(raw_tweet_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an aggregate table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_agg = pd.read_csv(raw_tweet_path2 + \"/\" + filename_list2[0])\n",
    "company_name = filename_list2[0][3:-4]\n",
    "df_agg[\"Company_name\"] = [company_name for i in range(df_agg.shape[0])]\n",
    "\n",
    "for i in range(1, len(filename_list2)):\n",
    "    df = pd.read_csv(raw_tweet_path2 + \"/\" + filename_list2[i])\n",
    "    company_name = filename_list2[i][3:-4]\n",
    "    df[\"Company_name\"] = [company_name for i in range(df.shape[0])]\n",
    "    df_agg = pd.concat([df_agg, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914523, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the sentiment analysis. The final file is saved to `df_user_based_tweets1_features_added.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Text_to_Features_Script as script     # A different version, with the proper things commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n"
     ]
    }
   ],
   "source": [
    "script.main(df_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Data_Preprocessed/df_tweets_processed_Shashank.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'entities_cashtags', 'entities_hashtags', 'entities_urls',\n",
       "       'public_metrics_like_count', 'public_metrics_quote_count',\n",
       "       'public_metrics_reply_count', 'public_metrics_retweet_count', 'text',\n",
       "       'entities_mentions', 'created_at_user',\n",
       "       'public_metrics_followers_count', 'public_metrics_following_count',\n",
       "       'public_metrics_listed_count', 'public_metrics_tweet_count',\n",
       "       'media_type', 'Company_name', 'Word_count_News_agencies',\n",
       "       'Word_count_Henry08_pos', 'Word_count_Henry08_neg',\n",
       "       'Word_count_LM11_pos', 'Word_count_LM11_neg',\n",
       "       'Word_count_Hagenau13_pos', 'Word_count_Hagenau13_neg',\n",
       "       'Tweet_Length_characters', 'Tweet_Length_words', 'Compound_vader',\n",
       "       'Positive_vader', 'Negative_vader', 'Neutral_vader'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Word_count_News_agencies</th>\n",
       "      <th>Word_count_Henry08_pos</th>\n",
       "      <th>Word_count_Henry08_neg</th>\n",
       "      <th>Word_count_LM11_pos</th>\n",
       "      <th>Word_count_LM11_neg</th>\n",
       "      <th>Word_count_Hagenau13_pos</th>\n",
       "      <th>Word_count_Hagenau13_neg</th>\n",
       "      <th>Tweet_Length_characters</th>\n",
       "      <th>Tweet_Length_words</th>\n",
       "      <th>Compound_vader</th>\n",
       "      <th>Positive_vader</th>\n",
       "      <th>Negative_vader</th>\n",
       "      <th>Neutral_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ceridian</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ceridian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ceridian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ceridian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ceridian</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914518</th>\n",
       "      <td>PackagingCorporationofAmerica</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>57</td>\n",
       "      <td>-0.8207</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914519</th>\n",
       "      <td>PackagingCorporationofAmerica</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914520</th>\n",
       "      <td>PackagingCorporationofAmerica</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914521</th>\n",
       "      <td>PackagingCorporationofAmerica</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>28</td>\n",
       "      <td>0.4753</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914522</th>\n",
       "      <td>PackagingCorporationofAmerica</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914523 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Company_name  Word_count_News_agencies  \\\n",
       "0                            Ceridian                         0   \n",
       "1                            Ceridian                         0   \n",
       "2                            Ceridian                         0   \n",
       "3                            Ceridian                         0   \n",
       "4                            Ceridian                         0   \n",
       "...                               ...                       ...   \n",
       "914518  PackagingCorporationofAmerica                         0   \n",
       "914519  PackagingCorporationofAmerica                         0   \n",
       "914520  PackagingCorporationofAmerica                         0   \n",
       "914521  PackagingCorporationofAmerica                         0   \n",
       "914522  PackagingCorporationofAmerica                         0   \n",
       "\n",
       "        Word_count_Henry08_pos  Word_count_Henry08_neg  Word_count_LM11_pos  \\\n",
       "0                            1                       0                    0   \n",
       "1                            0                       0                    0   \n",
       "2                            0                       0                    0   \n",
       "3                            0                       0                    0   \n",
       "4                            1                       1                    0   \n",
       "...                        ...                     ...                  ...   \n",
       "914518                       0                       0                    1   \n",
       "914519                       0                       0                    0   \n",
       "914520                       0                       0                    0   \n",
       "914521                       1                       0                    1   \n",
       "914522                       0                       0                    0   \n",
       "\n",
       "        Word_count_LM11_neg  Word_count_Hagenau13_pos  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "...                     ...                       ...   \n",
       "914518                    4                         0   \n",
       "914519                    0                         0   \n",
       "914520                    0                         0   \n",
       "914521                    0                         0   \n",
       "914522                    0                         0   \n",
       "\n",
       "        Word_count_Hagenau13_neg  Tweet_Length_characters  Tweet_Length_words  \\\n",
       "0                              0                      119                  21   \n",
       "1                              0                      159                  31   \n",
       "2                              0                       94                  12   \n",
       "3                              0                      156                  31   \n",
       "4                              1                       98                  19   \n",
       "...                          ...                      ...                 ...   \n",
       "914518                         0                      274                  57   \n",
       "914519                         0                      128                  22   \n",
       "914520                         0                      167                  29   \n",
       "914521                         0                      160                  28   \n",
       "914522                         0                      200                  38   \n",
       "\n",
       "        Compound_vader  Positive_vader  Negative_vader  Neutral_vader  \n",
       "0               0.0000           0.000           0.000          1.000  \n",
       "1               0.0000           0.000           0.000          1.000  \n",
       "2               0.0000           0.000           0.000          1.000  \n",
       "3               0.0000           0.000           0.000          1.000  \n",
       "4              -0.2732           0.000           0.149          0.851  \n",
       "...                ...             ...             ...            ...  \n",
       "914518         -0.8207           0.000           0.163          0.837  \n",
       "914519         -0.2023           0.000           0.122          0.878  \n",
       "914520          0.0000           0.000           0.000          1.000  \n",
       "914521          0.4753           0.128           0.000          0.872  \n",
       "914522          0.0000           0.000           0.000          1.000  \n",
       "\n",
       "[914523 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Company_name', 'Word_count_News_agencies',\n",
    "       'Word_count_Henry08_pos', 'Word_count_Henry08_neg',\n",
    "       'Word_count_LM11_pos', 'Word_count_LM11_neg',\n",
    "       'Word_count_Hagenau13_pos', 'Word_count_Hagenau13_neg',\n",
    "       'Tweet_Length_characters', 'Tweet_Length_words', 'Compound_vader',\n",
    "       'Positive_vader', 'Negative_vader', 'Neutral_vader']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregate table is too large to put onto GitHub as a single file. So, we split it into two below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all = pd.read_parquet(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Data_Preprocessed/df_tweets_Shashank_features_added.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914523, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_all.loc[df_all.index < 500000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_all.loc[df_all.index >= 500000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414523, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_parquet(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Data_Preprocessed/df_tweets_Shashank_features_added_part1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_parquet(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Data_Preprocessed/df_tweets_Shashank_features_added_part2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
